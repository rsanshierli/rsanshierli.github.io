<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>《Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism》记录 | 想吃煎饼果子</title><meta name="description" content="《Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism》记录"><meta name="keywords" content="论文记录,NLP"><meta name="author" content="R"><meta name="copyright" content="R"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="《Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism》记录"><meta name="twitter:description" content="《Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism》记录"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta property="og:type" content="article"><meta property="og:title" content="《Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism》记录"><meta property="og:url" content="http://yoursite.com/2020/03/04/article-4/"><meta property="og:site_name" content="想吃煎饼果子"><meta property="og:description" content="《Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism》记录"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="http://yoursite.com/2020/03/04/article-4/"><link rel="prev" title="《Chinese Open Relation Extraction and Knowledge Base Establishment》阅读记录" href="http://yoursite.com/2020/03/04/article-5/"><link rel="next" title="《Effective Modeling of Encoder-Decoder Architecturefor Joint Entity and Relation Extraction》" href="http://yoursite.com/2020/03/04/article-3/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">想吃煎饼果子</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">6</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">2</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">1</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> List</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> Music</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> Movie</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">Catalog</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Abstract"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Abstract</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#null"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">Introduction</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#null"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">Model</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#null"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">OneDecoder Model</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#null"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text">MultiDecoder Model</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#null"><span class="toc_mobile_items-number">3.3.</span> <span class="toc_mobile_items-text">&amp;nbsp;</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#null"><span class="toc-number">3.</span> <span class="toc-text">Model</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-number">3.1.</span> <span class="toc-text">OneDecoder Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-number">3.2.</span> <span class="toc-text">MultiDecoder Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#null"><span class="toc-number">3.3.</span> <span class="toc-text">&amp;nbsp;</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png)"><div id="post-info"><div id="post-title"><div class="posttitle">《Extracting Relational Facts by an End-to-End Neural Model with Copy Mechanism》记录</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> Created 2020-03-04<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> Updated 2020-03-04</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%AC%94%E8%AE%B0/">笔记</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>Post View:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>​       句子中的关系事实通常很复杂，不同的关系三元组在句子中存有实体重叠。根据三元组重叠度将句子分为三种类型，包括Normal，EntityPairOverlap 和 SingleEntiyOverlap。 现有方法主要集中在Normal类上，无法准确地提取关系三元组。 本文提出了一种基于具有复制机制的序列到序列学习的端到端模型，该模型可以从任何这些类的句子中联合提取相关事实。 在解码过程中，采用两种不同的策略：仅使用一个联合解码器或应用多个分离解码器。</p>
<a id="more"></a>

<h1 style="text-indent:0px;"><a name="t1"></a><a name="t1"></a>Introduction</h1>
<p style="text-indent:33px;">句子中的关系事实常常很复杂，不同的关系三元组在句子中可能有重叠。如果一个句子的三元组都没有重叠的实体，则该句子属于Normal类；如果一个句子的某些三元组中的某些实体对重叠，则该句子属于EntityPairOverlap（EPO）类；如果一个句子的某些三元组中有一个重叠的实体，而这些三元组中没有重叠的实体对，则该句子属于SingleEntityOverlap（SEO）类。</p>
<p style="text-align:center;"><a href="https://img-blog.csdnimg.cn/20191223154146830.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt class="has lazyload" height="462" width="550" title data-src="https://img-blog.csdnimg.cn/20191223154146830.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70"></a></p>
<p style="text-indent:33px;">为了处理三元组重叠的问题，必须允许一个实体自由地参与多个三元组，对此论文提出一种基于<strong>复制机制</strong>的序列到序列学习的端到端模型，该模型可以从包含这些类别的句子中联合提取相关事实。此模型的主要组件包括两部分：<strong>编码器和解码器</strong>。编码器将自然语言句子（源句子）转换为固定长度的语义向量，然后解码器读入此向量并直接生成三元组。为了生成一个三元组，首先解码器生成关系；其次通过采用复制机制，解码器从源句子复制第一个实体（头实体）；最后解码器从源句子中复制第二个实体（尾实体），以此来提取多个三元组。解码过程中采用两种不同的策略：仅使用一个统一解码器（OneDecoder）生成所有三元组，应用多个分离解码器（MultiDecoder）其每个解码器生成一个三元组。</p>
<h1 style="text-indent:0px;"><a name="t2"></a><a name="t2"></a>Model</h1>
<h2><a name="t3"></a><a name="t3"></a>OneDecoder Model</h2>
<p style="text-align:center;"><a href="https://img-blog.csdnimg.cn/20191223162423231.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt class="has lazyload" height="846" width="1100" title data-src="https://img-blog.csdnimg.cn/20191223162423231.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70"></a></p>
<blockquote>
<p style="text-indent:0;">Figure 2: The overall structure of OneDecoder model. A bi-directional RNN is used to encode the source sentence and then a decoder is used to generate triples directly. The relation is predicted and the entity is copied from source sentence.</p>
</blockquote>

<p style="text-indent:0;"><strong>Encoder&nbsp; &nbsp;&nbsp;</strong>首先将源句子转换为矩阵，矩阵向量表示各个词嵌入，依序将矩阵传入Bi-RNN生成时间步 t 时刻的结果和隐藏状态。输出结果为&nbsp;<a href="https://private.codecogs.com/gif.latex?O%5E%7BE%7D%3D%20%5Cleft%20%5B%20o_%7B1%7D%5E%7BE%7D%2C%5Ccdots%20%2Co_%7Bn%7D%5E%7BE%7D%20%5Cright%20%5D%2Co_%7Bt%7D%5E%7BE%7D%3D%5Cleft%20%5B%20%5Coverrightarrow%7Bo_%7Bt%7D%5E%7BE%7D%7D%2C%5Coverleftarrow%7Bo_%7Bn-t&amp;plus;1%7D%5E%7BE%7D%7D%20%5Cright%20%5D" target="_blank" rel="noopener" data-fancybox="group" data-caption="O^{E}= \left [ o_{1}^{E},\cdots ,o_{n}^{E} \right ],o_{t}^{E}=\left [ \overrightarrow{o_{t}^{E}},\overleftarrow{o_{n-t+1}^{E}} \right ]" class="fancybox"><img alt="O^{E}= \left [ o_{1}^{E},\cdots ,o_{n}^{E} \right ],o_{t}^{E}=\left [ \overrightarrow{o_{t}^{E}},\overleftarrow{o_{n-t+1}^{E}} \right ]" class="mathcode lazyload" title="O^{E}= \left [ o_{1}^{E},\cdots ,o_{n}^{E} \right ],o_{t}^{E}=\left [ \overrightarrow{o_{t}^{E}},\overleftarrow{o_{n-t+1}^{E}} \right ]" data-src="https://private.codecogs.com/gif.latex?O%5E%7BE%7D%3D%20%5Cleft%20%5B%20o_%7B1%7D%5E%7BE%7D%2C%5Ccdots%20%2Co_%7Bn%7D%5E%7BE%7D%20%5Cright%20%5D%2Co_%7Bt%7D%5E%7BE%7D%3D%5Cleft%20%5B%20%5Coverrightarrow%7Bo_%7Bt%7D%5E%7BE%7D%7D%2C%5Coverleftarrow%7Bo_%7Bn-t&amp;plus;1%7D%5E%7BE%7D%7D%20%5Cright%20%5D"></a>，隐藏状态的表示类似。</p>
<p style="text-indent:0;"><strong>Decoder&nbsp;</strong>&nbsp; &nbsp;首先解码器生成三元组的关系，其次解码器从源句子中复制一个实体作为三元组的第一个实体，最后解码器从源句子中复制第二个实体。重复此过程，解码器可以生成多个三元组。当生成所有有效的三元组，解码器将生成NA三元组，即意味着“停止”。NA三元组由NA关系和NA实体对组成。</p>
<p style="text-align:center;"><a href="https://img-blog.csdnimg.cn/20191223165415874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt class="has lazyload" height="373" width="901" title data-src="https://img-blog.csdnimg.cn/20191223165415874.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70"></a></p>
<blockquote>
<p style="text-indent:0;">Figure 3: The inputs and outputs of the decoder(s) of OneDecoder model and MultiDecoder model. (a) is the decoder of OneDecoder model. As we can see, only one decoder (the green rectangle with shadows) is used and this encoder is initialized with the sentence representation s. (b) is the decoders of MultiDecoder model. There are two decoders (the green rectangle and blue rectangle with shadows). The ﬁrst decoder is initialized with s;Other decoder(s) are initialized with s and previous decoder’s state.</p>
</blockquote>

<p style="text-indent:0;">解码计算：<a href="https://private.codecogs.com/gif.latex?o_%7Bt%7D%5E%7BD%7D%2Ch_%7Bt%7D%5E%7BD%7D%20%3D%20g%5Cleft%20%28%20u_%7Bt%7D%2C%20h_%7Bt-1%7D%5E%7BD%7D%20%5Cright%20%29" target="_blank" rel="noopener" data-fancybox="group" data-caption="o_{t}^{D},h_{t}^{D} = g\left ( u_{t}, h_{t-1}^{D} \right )" class="fancybox"><img alt="o_{t}^{D},h_{t}^{D} = g\left ( u_{t}, h_{t-1}^{D} \right )" class="mathcode lazyload" title="o_{t}^{D},h_{t}^{D} = g\left ( u_{t}, h_{t-1}^{D} \right )" data-src="https://private.codecogs.com/gif.latex?o_%7Bt%7D%5E%7BD%7D%2Ch_%7Bt%7D%5E%7BD%7D%20%3D%20g%5Cleft%20%28%20u_%7Bt%7D%2C%20h_%7Bt-1%7D%5E%7BD%7D%20%5Cright%20%29"></a>，其中&nbsp;<a href="https://private.codecogs.com/gif.latex?h_%7B0%7D%5E%7BD%7D" target="_blank" rel="noopener" data-fancybox="group" data-caption="h_{0}^{D}" class="fancybox"><img alt="h_{0}^{D}" class="mathcode lazyload" title="h_{0}^{D}" data-src="https://private.codecogs.com/gif.latex?h_%7B0%7D%5E%7BD%7D"></a>&nbsp;为源句子的初始化表示，<a href="https://private.codecogs.com/gif.latex?u_%7Bt%7D%3D%5Cleft%20%5B%20v_%7Bt%7D%3Bc_%7Bt%7D%20%5Cright%20%5D%5Ccdot%20W%5E%7Bu%7D" target="_blank" rel="noopener" data-fancybox="group" data-caption="u_{t}=\left [ v_{t};c_{t} \right ]\cdot W^{u}" class="fancybox"><img alt="u_{t}=\left [ v_{t};c_{t} \right ]\cdot W^{u}" class="mathcode lazyload" title="u_{t}=\left [ v_{t};c_{t} \right ]\cdot W^{u}" data-src="https://private.codecogs.com/gif.latex?u_%7Bt%7D%3D%5Cleft%20%5B%20v_%7Bt%7D%3Bc_%7Bt%7D%20%5Cright%20%5D%5Ccdot%20W%5E%7Bu%7D"></a>，<a href="https://private.codecogs.com/gif.latex?c_%7Bt%7D" target="_blank" rel="noopener" data-fancybox="group" data-caption="c_{t}" class="fancybox"><img alt="c_{t}" class="mathcode lazyload" title="c_{t}" data-src="https://private.codecogs.com/gif.latex?c_%7Bt%7D"></a>&nbsp;是注意力向量，<a href="https://private.codecogs.com/gif.latex?v_%7Bt%7D" target="_blank" rel="noopener" data-fancybox="group" data-caption="v_{t}" class="fancybox"><img alt="v_{t}" class="mathcode lazyload" title="v_{t}" data-src="https://private.codecogs.com/gif.latex?v_%7Bt%7D"></a>&nbsp;是复制实体或者前一时刻预测关系的嵌入。</p>
<p style="text-align:center;"><a href="https://img-blog.csdnimg.cn/20191223170330403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt class="has lazyload" height="259" width="400" title data-src="https://img-blog.csdnimg.cn/20191223170330403.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTMxMTgx,size_16,color_FFFFFF,t_70"></a></p>
<p style="text-indent:33px;">在获得时间步 t 时得解码结果&nbsp;<a href="https://private.codecogs.com/gif.latex?o_%7Bt%7D%5E%7BD%7D" target="_blank" rel="noopener" data-fancybox="group" data-caption="o_{t}^{D}" class="fancybox"><img alt="o_{t}^{D}" class="mathcode lazyload" title="o_{t}^{D}" data-src="https://private.codecogs.com/gif.latex?o_%7Bt%7D%5E%7BD%7D"></a>&nbsp;后，如果 t 能除以3余1则进行一次关系预测，如果余2则从源句子中复制第一个实体，整除则复制第二个实体。</p>
<p style="text-indent:0;"><strong>Predict Relation</strong>&nbsp; &nbsp; 假设有m个有效关系，使用一个全连接层来计算所有有效关系的置信向量，<a href="https://private.codecogs.com/gif.latex?q%5E%7Br%7D%3Dselu%5Cleft%20%28%20o_%7Bt%7D%5E%7BD%7D%5Ccdot%20W%5E%7Bt%7D&amp;plus;b%5E%7Br%7D%20%5Cright%20%29" target="_blank" rel="noopener" data-fancybox="group" data-caption="q^{r}=selu\left ( o_{t}^{D}\cdot W^{t}+b^{r} \right )" class="fancybox"><img alt="q^{r}=selu\left ( o_{t}^{D}\cdot W^{t}+b^{r} \right )" class="mathcode lazyload" title="q^{r}=selu\left ( o_{t}^{D}\cdot W^{t}+b^{r} \right )" data-src="https://private.codecogs.com/gif.latex?q%5E%7Br%7D%3Dselu%5Cleft%20%28%20o_%7Bt%7D%5E%7BD%7D%5Ccdot%20W%5E%7Bt%7D&amp;plus;b%5E%7Br%7D%20%5Cright%20%29"></a>。在生成NA三元组时，NA关系的置信值计算为：<a href="https://private.codecogs.com/gif.latex?q%5E%7BNA%7D%3Dselu%5Cleft%20%28%20o_%7Bt%7D%5E%7BD%7D%5Ccdot%20W%5E%7BNA%7D&amp;plus;b%5E%7BNA%7D%20%5Cright%20%29" target="_blank" rel="noopener" data-fancybox="group" data-caption="q^{NA}=selu\left ( o_{t}^{D}\cdot W^{NA}+b^{NA} \right )" class="fancybox"><img alt="q^{NA}=selu\left ( o_{t}^{D}\cdot W^{NA}+b^{NA} \right )" class="mathcode lazyload" title="q^{NA}=selu\left ( o_{t}^{D}\cdot W^{NA}+b^{NA} \right )" data-src="https://private.codecogs.com/gif.latex?q%5E%7BNA%7D%3Dselu%5Cleft%20%28%20o_%7Bt%7D%5E%7BD%7D%5Ccdot%20W%5E%7BNA%7D&amp;plus;b%5E%7BNA%7D%20%5Cright%20%29"></a>。然后获得概率分布表示：<a href="https://private.codecogs.com/gif.latex?p%5E%7Br%7D%3Dsoftmax%5Cleft%20%28%20%5Cleft%20%5B%20q%5E%7Br%7D%3Bq%5E%7BNA%7D%20%5Cright%20%5D%20%5Cright%20%29" target="_blank" rel="noopener" data-fancybox="group" data-caption="p^{r}=softmax\left ( \left [ q^{r};q^{NA} \right ] \right )" class="fancybox"><img alt="p^{r}=softmax\left ( \left [ q^{r};q^{NA} \right ] \right )" class="mathcode lazyload" title="p^{r}=softmax\left ( \left [ q^{r};q^{NA} \right ] \right )" data-src="https://private.codecogs.com/gif.latex?p%5E%7Br%7D%3Dsoftmax%5Cleft%20%28%20%5Cleft%20%5B%20q%5E%7Br%7D%3Bq%5E%7BNA%7D%20%5Cright%20%5D%20%5Cright%20%29"></a>，选择最高概率的关系并将其嵌入作为下一步的输入。</p>
<p style="text-indent:0;"><strong>Copy the First Entity</strong>&nbsp; &nbsp; 实体的选择跟关系预测的计算相似，选择概率分布中的最高概率作为预测实体，同样使用其嵌入作为下一步的输入。概率分布表示为：<a href="https://private.codecogs.com/gif.latex?p%5E%7Be%7D%3Dsoftmax%5Cleft%20%28%20%5Cleft%20%5B%20q%5E%7Be%7D%3Bq%5E%7BNA%7D%20%5Cright%20%5D%20%5Cright%20%29" target="_blank" rel="noopener" data-fancybox="group" data-caption="p^{e}=softmax\left ( \left [ q^{e};q^{NA} \right ] \right )" class="fancybox"><img alt="p^{e}=softmax\left ( \left [ q^{e};q^{NA} \right ] \right )" class="mathcode lazyload" title="p^{e}=softmax\left ( \left [ q^{e};q^{NA} \right ] \right )" data-src="https://private.codecogs.com/gif.latex?p%5E%7Be%7D%3Dsoftmax%5Cleft%20%28%20%5Cleft%20%5B%20q%5E%7Be%7D%3Bq%5E%7BNA%7D%20%5Cright%20%5D%20%5Cright%20%29"></a>；置信向量为：<a href="https://private.codecogs.com/gif.latex?q_%7Bi%7D%5E%7Be%7D%3Dselu%5Cleft%20%28%20%5Cleft%20%5B%20o_%7Bt%7D%5E%7BD%7D%3Bo_%7Bi%7D%5E%7BE%7D%20%5Cright%20%5D%20%5Ccdot%20W%5E%7Be%7D%20%5Cright%20%29" target="_blank" rel="noopener" data-fancybox="group" data-caption="q_{i}^{e}=selu\left ( \left [ o_{t}^{D};o_{i}^{E} \right ] \cdot W^{e} \right )" class="fancybox"><img alt="q_{i}^{e}=selu\left ( \left [ o_{t}^{D};o_{i}^{E} \right ] \cdot W^{e} \right )" class="mathcode lazyload" title="q_{i}^{e}=selu\left ( \left [ o_{t}^{D};o_{i}^{E} \right ] \cdot W^{e} \right )" data-src="https://private.codecogs.com/gif.latex?q_%7Bi%7D%5E%7Be%7D%3Dselu%5Cleft%20%28%20%5Cleft%20%5B%20o_%7Bt%7D%5E%7BD%7D%3Bo_%7Bi%7D%5E%7BE%7D%20%5Cright%20%5D%20%5Ccdot%20W%5E%7Be%7D%20%5Cright%20%29"></a>。</p>
<p style="text-indent:0;"><strong>Copy the Second Entity</strong>&nbsp; &nbsp; 第二个实体的复制必须避开已复制的第一个实体，对此，假设第一个实体为k-th，引入一个长度为源句子长度n的掩码向量M，<a href="https://private.codecogs.com/gif.latex?M_%7Bi%7D%3D1%2Ci%5Cneq%20k%2CM_%7Bi%7D%3D0%2Ci%3Dk" target="_blank" rel="noopener" data-fancybox="group" data-caption="M_{i}=1,i\neq k,M_{i}=0,i=k" class="fancybox"><img alt="M_{i}=1,i\neq k,M_{i}=0,i=k" class="mathcode lazyload" title="M_{i}=1,i\neq k,M_{i}=0,i=k" data-src="https://private.codecogs.com/gif.latex?M_%7Bi%7D%3D1%2Ci%5Cneq%20k%2CM_%7Bi%7D%3D0%2Ci%3Dk"></a>。然后计算概率分布，<a href="https://private.codecogs.com/gif.latex?p%5E%7Be%7D%3Dsoftmax%5Cleft%20%28%20%5Cleft%20%5B%20M%5Cotimes%20q%5E%7Be%7D%3Bq%5E%7BNA%7D%20%5Cright%20%5D%20%5Cright%20%29" target="_blank" rel="noopener" data-fancybox="group" data-caption="p^{e}=softmax\left ( \left [ M\otimes q^{e};q^{NA} \right ] \right )" class="fancybox"><img alt="p^{e}=softmax\left ( \left [ M\otimes q^{e};q^{NA} \right ] \right )" class="mathcode lazyload" title="p^{e}=softmax\left ( \left [ M\otimes q^{e};q^{NA} \right ] \right )" data-src="https://private.codecogs.com/gif.latex?p%5E%7Be%7D%3Dsoftmax%5Cleft%20%28%20%5Cleft%20%5B%20M%5Cotimes%20q%5E%7Be%7D%3Bq%5E%7BNA%7D%20%5Cright%20%5D%20%5Cright%20%29"></a>，⊗是逐个元素相乘。</p>
<h2 style="text-indent:0px;"><a name="t4"></a><a name="t4"></a>MultiDecoder Model</h2>
<p style="text-indent:33px;">MultiDecoder模型是所提出的OneDecoder模型的扩展。主要区别在于解码三元组时，MultiDecoder模型使用几个分离的解码器进行解码。图3（b）显示了MultiDecoder模型的解码器的输入和输出，有两个解码器（带阴影的绿色和蓝色矩形），解码器按顺序工作：第一个解码器生成第一个三元组，然后第二个解码器生成第二个三元组。</p>
<p style="text-align:center;"><a href="https://img-blog.csdnimg.cn/20191224103136129.png" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt class="has lazyload" height="107" width="500" title data-src="https://img-blog.csdnimg.cn/20191224103136129.png"></a></p>
<p style="text-indent:0;"><a href="https://private.codecogs.com/gif.latex?D_%7Bi%7D" target="_blank" rel="noopener" data-fancybox="group" data-caption="D_{i}" class="fancybox"><img alt="D_{i}" class="mathcode lazyload" title="D_{i}" data-src="https://private.codecogs.com/gif.latex?D_%7Bi%7D"></a>&nbsp;表示第 i 个解码器，ut 计算跟之前一样，初始化隐藏状态计算如下：</p>
<p style="text-align:center;"><a href="https://img-blog.csdnimg.cn/20191224103253460.png" target="_blank" rel="noopener" data-fancybox="group" data-caption class="fancybox"><img alt class="has lazyload" height="110" width="400" title data-src="https://img-blog.csdnimg.cn/20191224103253460.png"></a></p>
<h2 style="text-indent:0px;"><a name="t5"></a><a name="t5"></a>&nbsp;</h2>
<p>&nbsp;</p></div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">R</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2020/03/04/article-4/">http://yoursite.com/2020/03/04/article-4/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/">论文记录    </a><a class="post-meta__tags" href="/tags/NLP/">NLP    </a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.jpg" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/03/04/article-5/"><img class="prev_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Previous Post</div><div class="prev_info"><span>《Chinese Open Relation Extraction and Knowledge Base Establishment》阅读记录</span></div></a></div><div class="next-post pull_right"><a href="/2020/03/04/article-3/"><img class="next_cover lazyload" data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">Next Post</div><div class="next_info"><span>《Effective Modeling of Encoder-Decoder Architecturefor Joint Entity and Relation Extraction》</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommend</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/03/04/article-2/" title="《Graph Neural Networks with Generated Parameters for Relation Extraction》阅读笔记"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-03-04</div><div class="relatedPosts_title">《Graph Neural Networks with Generated Parameters for Relation Extraction》阅读笔记</div></div></a></div><div class="relatedPosts_item"><a href="/2020/03/04/article-1/" title="《GraphRel：Modeling Text as Relational Graphs for Joint Entity and Relation Extraction》阅读记录"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-03-04</div><div class="relatedPosts_title">《GraphRel：Modeling Text as Relational Graphs for Joint Entity and Relation Extraction》阅读记录</div></div></a></div><div class="relatedPosts_item"><a href="/2020/03/04/article-3/" title="《Effective Modeling of Encoder-Decoder Architecturefor Joint Entity and Relation Extraction》"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-03-04</div><div class="relatedPosts_title">《Effective Modeling of Encoder-Decoder Architecturefor Joint Entity and Relation Extraction》</div></div></a></div><div class="relatedPosts_item"><a href="/2020/03/04/article-5/" title="《Chinese Open Relation Extraction and Knowledge Base Establishment》阅读记录"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-03-04</div><div class="relatedPosts_title">《Chinese Open Relation Extraction and Knowledge Base Establishment》阅读记录</div></div></a></div><div class="relatedPosts_item"><a href="/2020/03/04/article/" title="《Attention Guided Graph Convolutional Networks for Relation Extraction》阅读记录"><img class="relatedPosts_cover lazyload"data-src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/top_img/default.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-03-04</div><div class="relatedPosts_title">《Attention Guided Graph Convolutional Networks for Relation Extraction》阅读记录</div></div></a></div></div><div class="clear_both"></div></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By R</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="Traditional Chinese and Simplified Chinese Conversion" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script></body></html>